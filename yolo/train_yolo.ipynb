{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class DatasetConfig:\n",
    "    IMAGE_SIZE:     int   = 1280\n",
    "    BATCH_SIZE:     int   = -1\n",
    "    CLOSE_MOSAIC:   int   = 10\n",
    "    MOSAIC:         float = 0.3\n",
    "    FLIP_LR:        float = 0.5 # Turn off horizontal flip.\n",
    "    HSV_H:          float = 0.3\n",
    "    HSV_S:          float = 0.3\n",
    "    HSV_V:          float = 0.3\n",
    "    ROTATION:       float = 0.2\n",
    "    TRANSLATION:    float = 0.2\n",
    "    SCALE:          float = 0.2\n",
    "    SHEAR:          float = 0.2\n",
    "    PERSPECTIVE:    float = 0\n",
    "    FLIP_UD:        float = 0\n",
    "    MIXUP:          float = 0\n",
    "    ERASING:        float = 0.2\n",
    "    CROP_FRACTION:  float = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    DATASET_YAML:   str = \"bone-keypoints.yaml\"\n",
    "    MODEL:          str = \"yolov8m-pose.pt\"\n",
    "    EPOCHS:         int = 100\n",
    "    KPT_SHAPE:    tuple = (11,3)\n",
    "    PROJECT:        str = \"Bone_keypoints\"\n",
    "    NAME:           str = f\"{MODEL.split('.')[0]}_{EPOCHS}_epochs_no_aug\"\n",
    "    CLASSES_DICT:  dict = field(default_factory = lambda:{0 : \"bone\"})\n",
    "    BOX_WEIGHT:     float = 1.5\n",
    "    CLS_WEIGHT:     float = 0.1\n",
    "    POSE_WEIGHT:    float = 20.0\n",
    "    DROP_OUT:       float = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = \"./bone-pose-data\"\n",
    " \n",
    "TRAIN_DIR         = f\"train\"\n",
    "TRAIN_FOLDER_IMG    = f\"images\"\n",
    "TRAIN_FOLDER_LABELS = f\"labels\"\n",
    " \n",
    "TRAIN_IMG_PATH   = os.path.join(DATA_DIR, TRAIN_DIR, TRAIN_FOLDER_IMG)\n",
    "TRAIN_LABEL_PATH = os.path.join(DATA_DIR, TRAIN_DIR, TRAIN_FOLDER_LABELS)\n",
    " \n",
    "VALID_DIR           = f\"valid\"\n",
    "VALID_FOLDER_IMG    = f\"images\"\n",
    "VALID_FOLDER_LABELS = f\"labels\"\n",
    " \n",
    "VALID_IMG_PATH   = os.path.join(DATA_DIR, VALID_DIR, VALID_FOLDER_IMG)\n",
    "VALID_LABEL_PATH = os.path.join(DATA_DIR, VALID_DIR, VALID_FOLDER_LABELS)\n",
    " \n",
    "os.makedirs(TRAIN_IMG_PATH, exist_ok=True)\n",
    "os.makedirs(TRAIN_LABEL_PATH, exist_ok=True)\n",
    "os.makedirs(VALID_IMG_PATH, exist_ok=True)\n",
    "os.makedirs(VALID_LABEL_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = TrainingConfig()\n",
    "data_config = DatasetConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetConfig(IMAGE_SIZE=1280, BATCH_SIZE=-1, CLOSE_MOSAIC=10, MOSAIC=0.3, FLIP_LR=0.5, HSV_H=0.3, HSV_S=0.3, HSV_V=0.3, ROTATION=0.2, TRANSLATION=0.2, SCALE=0.2, SHEAR=0.2, PERSPECTIVE=0.2, FLIP_UD=0, MIXUP=0.2, ERASING=0.2, CROP_FRACTION=0.2)\n"
     ]
    }
   ],
   "source": [
    "print(data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "current_dir = os.getcwd()\n",
    " \n",
    "data_dict = dict(\n",
    "                path      = os.path.join(current_dir, DATA_DIR),\n",
    "                train     = os.path.join(TRAIN_DIR, TRAIN_FOLDER_IMG),\n",
    "                val       = os.path.join(VALID_DIR, VALID_FOLDER_IMG),\n",
    "                names     = train_config.CLASSES_DICT,\n",
    "                kpt_shape = list(train_config.KPT_SHAPE),\n",
    "               )\n",
    " \n",
    "with open(train_config.DATASET_YAML, \"w\") as config_file:\n",
    "    yaml.dump(data_dict, config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.58 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.50 🚀 Python-3.11.6 torch-2.3.1 CUDA:0 (NVIDIA RTX A4000, 16102MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=pose, mode=train, model=yolov8m-pose.pt, data=bone-keypoints.yaml, epochs=100, time=None, patience=100, batch=-1, imgsz=1280, save=True, save_period=-1, cache=False, device=None, workers=8, project=Bone_keypoints, name=yolov8m-pose_100_epochs_no_aug4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.2, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=1.5, cls=0.1, dfl=1.5, pose=20.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.3, hsv_s=0.3, hsv_v=0.3, degrees=0.2, translate=0.2, scale=0.2, shear=0.2, perspective=0.2, flipud=0, fliplr=0.5, bgr=0.0, mosaic=0.3, mixup=0.2, copy_paste=0.0, auto_augment=randaugment, erasing=0.2, crop_fraction=0.2, cfg=None, tracker=botsort.yaml, save_dir=Bone_keypoints/yolov8m-pose_100_epochs_no_aug4\n",
      "Overriding model.yaml kpt_shape=[17, 3] with kpt_shape=[11, 3]\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   4341574  ultralytics.nn.modules.head.Pose             [1, [11, 3], [192, 384, 576]] \n",
      "YOLOv8m-pose summary: 320 layers, 26422198 parameters, 26422182 gradients\n",
      "\n",
      "Transferred 481/517 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=1280 at 60.0% CUDA memory utilization.\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA RTX A4000) 15.72G total, 0.31G reserved, 0.24G allocated, 15.17G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    26422198           0         3.211         67.88           nan      (1, 3, 1280, 1280)                    list\n",
      "    26422198           0         6.006         81.16           nan      (2, 3, 1280, 1280)                    list\n",
      "    26422198           0        11.492         108.9           nan      (4, 3, 1280, 1280)                    list\n",
      "CUDA out of memory. Tried to allocate 76.00 MiB. GPU \n",
      "CUDA out of memory. Tried to allocate 76.00 MiB. GPU \n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 3 for CUDA:0 9.30G/15.72G (59%) ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /data/mah/boneyolo/bone-pose-data/train/labels.cache... 64 images, 0 backgrounds, 0 corrupt: 100%|██████████| 64/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ No 'flip_idx' array defined in data.yaml, setting augmentation 'fliplr=0.0'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /data/mah/boneyolo/bone-pose-data/valid/labels.cache... 8 images, 0 backgrounds, 0 corrupt: 100%|██████████| 8/8 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to Bone_keypoints/yolov8m-pose_100_epochs_no_aug4/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 83 weight(decay=0.0), 93 weight(decay=0.0004921875), 92 bias(decay=0.0)\n",
      "Image sizes 1280 train, 1280 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mBone_keypoints/yolov8m-pose_100_epochs_no_aug4\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      7.83G     0.2838      8.625     0.3417      12.88      1.698          0       1280: 100%|██████████| 22/22 [00:04<00:00,  4.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8          8      0.572      0.125       0.24      0.175          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100       5.2G     0.4064      10.62     0.4369      5.478      2.218          0       1280: 100%|██████████| 22/22 [00:04<00:00,  5.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  8.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8          8      0.572      0.125       0.24      0.175          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      5.44G     0.2275      5.734     0.2161     0.8773      1.183          0       1280: 100%|██████████| 22/22 [00:04<00:00,  5.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 13.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8          8      0.572      0.125       0.24      0.175          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      5.43G     0.2841      7.097     0.2396     0.5602      1.345          0       1280: 100%|██████████| 22/22 [00:04<00:00,  5.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 14.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          8          8      0.572      0.125       0.24      0.175          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[1;32m      3\u001b[0m pose_model \u001b[38;5;241m=\u001b[39m model \u001b[38;5;241m=\u001b[39m YOLO(train_config\u001b[38;5;241m.\u001b[39mMODEL)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mpose_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDATASET_YAML\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMAGE_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPROJECT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBOX_WEIGHT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLS_WEIGHT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpose\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPOSE_WEIGHT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhsv_h\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHSV_H\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhsv_s\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHSV_S\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhsv_v\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHSV_V\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdegrees\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mROTATION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtranslate\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRANSLATION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSCALE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshear\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSHEAR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43mperspective\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPERSPECTIVE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[43mflipud\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFLIP_UD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfliplr\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFLIP_LR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmosaic\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMOSAIC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmixup\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMIXUP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43merasing\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mERASING\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcrop_fraction\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCROP_FRACTION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDROP_OUT\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m           \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/mah/miniconda3/envs/boneyolo/lib/python3.11/site-packages/ultralytics/engine/model.py:650\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 650\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[0;32m/data/mah/miniconda3/envs/boneyolo/lib/python3.11/site-packages/ultralytics/engine/trainer.py:204\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/mah/miniconda3/envs/boneyolo/lib/python3.11/site-packages/ultralytics/engine/trainer.py:437\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;66;03m# Save model\u001b[39;00m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave \u001b[38;5;129;01mor\u001b[39;00m final_epoch:\n\u001b[0;32m--> 437\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_model_save\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;66;03m# Scheduler\u001b[39;00m\n",
      "File \u001b[0;32m/data/mah/miniconda3/envs/boneyolo/lib/python3.11/site-packages/ultralytics/engine/trainer.py:506\u001b[0m, in \u001b[0;36mBaseTrainer.save_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    503\u001b[0m serialized_ckpt \u001b[38;5;241m=\u001b[39m buffer\u001b[38;5;241m.\u001b[39mgetvalue()  \u001b[38;5;66;03m# get the serialized content to save\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;66;03m# Save checkpoints\u001b[39;00m\n\u001b[0;32m--> 506\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserialized_ckpt\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# save last.pt\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_fitness \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness:\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest\u001b[38;5;241m.\u001b[39mwrite_bytes(serialized_ckpt)  \u001b[38;5;66;03m# save best.pt\u001b[39;00m\n",
      "File \u001b[0;32m/data/mah/miniconda3/envs/boneyolo/lib/python3.11/pathlib.py:1067\u001b[0m, in \u001b[0;36mPath.write_bytes\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;66;03m# type-check for the buffer interface before truncating the file\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m view \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(data)\n\u001b[0;32m-> 1067\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mview\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "pose_model = model = YOLO(train_config.MODEL)\n",
    " \n",
    "pose_model.train(\n",
    "            data         = train_config.DATASET_YAML,\n",
    "            epochs       = train_config.EPOCHS,\n",
    "            imgsz        = data_config.IMAGE_SIZE,\n",
    "            batch        = data_config.BATCH_SIZE,\n",
    "            project      = train_config.PROJECT,\n",
    "            name         = train_config.NAME,\n",
    "            box          = train_config.BOX_WEIGHT,\n",
    "            cls          = train_config.CLS_WEIGHT,\n",
    "            pose         = train_config.POSE_WEIGHT,\n",
    "            hsv_h        = data_config.HSV_H,\n",
    "            hsv_s        = data_config.HSV_S,\n",
    "            hsv_v        = data_config.HSV_V,\n",
    "            degrees      = data_config.ROTATION,\n",
    "            translate    = data_config.TRANSLATION,\n",
    "            scale        = data_config.SCALE,\n",
    "            shear        = data_config.SHEAR,\n",
    "            perspective  = data_config.PERSPECTIVE,\n",
    "            flipud       = data_config.FLIP_UD,\n",
    "            fliplr       = data_config.FLIP_LR,\n",
    "            mosaic       = data_config.MOSAIC,\n",
    "            mixup        = data_config.MIXUP,\n",
    "            erasing      = data_config.ERASING,\n",
    "            crop_fraction = data_config.CROP_FRACTION,\n",
    "            dropout     = train_config.DROP_OUT\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /data/mah/boneyolo/bone-pose-data/valid/images/7_Oo_FM97985_L_f_d.jpg: 448x640 1 bone, 7.2ms\n",
      "Speed: 7.7ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mBone_keypoints/yolov8m-pose_100_epochs43\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'bone'}\n",
       " obb: None\n",
       " orig_img: array([[[153, 154, 152],\n",
       "         [154, 155, 153],\n",
       "         [157, 155, 154],\n",
       "         ...,\n",
       "         [125, 138, 146],\n",
       "         [126, 138, 148],\n",
       "         [128, 140, 150]],\n",
       " \n",
       "        [[155, 156, 154],\n",
       "         [153, 154, 152],\n",
       "         [156, 154, 153],\n",
       "         ...,\n",
       "         [128, 141, 149],\n",
       "         [127, 140, 148],\n",
       "         [127, 139, 149]],\n",
       " \n",
       "        [[154, 155, 153],\n",
       "         [154, 155, 153],\n",
       "         [153, 154, 152],\n",
       "         ...,\n",
       "         [128, 142, 148],\n",
       "         [127, 140, 148],\n",
       "         [128, 141, 149]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[152, 147, 144],\n",
       "         [153, 148, 145],\n",
       "         [153, 148, 145],\n",
       "         ...,\n",
       "         [132, 142, 149],\n",
       "         [134, 143, 147],\n",
       "         [133, 142, 146]],\n",
       " \n",
       "        [[153, 148, 145],\n",
       "         [152, 147, 144],\n",
       "         [152, 147, 144],\n",
       "         ...,\n",
       "         [134, 142, 149],\n",
       "         [135, 143, 150],\n",
       "         [134, 143, 147]],\n",
       " \n",
       "        [[151, 148, 144],\n",
       "         [152, 149, 145],\n",
       "         [152, 147, 144],\n",
       "         ...,\n",
       "         [135, 142, 151],\n",
       "         [134, 142, 149],\n",
       "         [135, 141, 148]]], dtype=uint8)\n",
       " orig_shape: (2136, 3216)\n",
       " path: '/data/mah/boneyolo/bone-pose-data/valid/images/7_Oo_FM97985_L_f_d.jpg'\n",
       " probs: None\n",
       " save_dir: 'Bone_keypoints/yolov8m-pose_100_epochs43'\n",
       " speed: {'preprocess': 7.747173309326172, 'inference': 7.178068161010742, 'postprocess': 1.0075569152832031}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict('./bone-pose-data/valid/images/7_Oo_FM97985_L_f_d.jpg', save=True, conf=0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boneyolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
